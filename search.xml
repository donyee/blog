<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[http的两个小优化]]></title>
    <url>%2F2019%2F12%2F03%2Fhttp%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%B0%8F%E4%BC%98%E5%8C%96.html</url>
    <content type="text"><![CDATA[一​ 近期项目测试发现一个小bug，值得记录一下；一个简单的http post 请求，使用了非规范的post 方式，大概是 post body 中放的是一堆k=v&amp;k=v，这样拼接的字符串，v还可能是json字符串；服务器端接受时获取body再写代码解析… 本来一切都正常，直到最近 v 是json，而且还有 = 号，导致服务器端解析报错；服务器端没做多个=号的判断，只是做了一个=号的split（摊手）；​ 这个bug的发现和解决都不复杂，修改了服务器端的解析方式即可初步解决；或者请求时多v再加一次url encode；我这里记录下主要是觉得这种post的方式有问题，直接post form 的形式会更好，而且服务器端是Spring mvc的，配置一下就可以直接获取参数，不需要再编码解析；​ 这种对http 理解不深，或者对 Spring mvc 的处理方式不熟悉，写的代码就是写一行留三个BUG；二​ 最近还看了一些OpenResty的资料，这种Ngixn + Luajit 的做一些http 的处理优化真的是非常的简单快捷、高性能；我对之前设计的一套网关架构也做了一些优化，准备把部分过滤检查功能用OpenResty 来实现；​ 之前的网关报文是json 格式的，放到http post body中请xian求的；我的优化方式是将业务无关的、报文共用的部分都放到 http header中，这样在解析http header时就可以处理过滤检查功能如唯一性检查、时间5分钟内限制检查；​ 签名方式也做优化，签名放到 http header 中，签名方式由header 中的参数+post body 组成k=v的格式生成签名，这样就是在验证签名是不用解析 post body；post body的处理完全由业务接口处理，降低网关处理逻辑和业务处理的耦合；​ 这种处理方式我之前和某银联开发项目时，对方的文档大概是这么描述的，但是直到我最近研究OpenResty才理解这些优化是怎么具体实现的，之前大概有些模糊的概念，而且Spring mvc处理时已经没法再考虑优化http header、post body这些，因为框架都处理完成了；三​ 昨天下午我看到有个测试在走被离职流程，下班时我买了两包烟给他，之前合作项目都挺愉快的；]]></content>
      <tags>
        <tag>http 网关</tag>
        <tag>post</tag>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作小结180811]]></title>
    <url>%2F2018%2F08%2F11%2Fweekly-4.html</url>
    <content type="text"><![CDATA[近期工作生活小结180811工作变化之前工作一直在广州总公司，今年公司的聚合支付业务都关闭；我做了一个月左右的小程序开发，但是合作方的业务流程一直拖着，小程序还没有上线；公司安排我到石家庄研究下区块链业务，看看能不能集成HF来实现一些创新；目前看还需要解决HF的权限问题…体重6月初来到石家庄，大概一个月后我的体重大概增加了8斤，233；顿时感觉压力好大，办了个100天的健身卡，隔天就去跑5KM，吃饭也控制了一下；哈哈哈 石家庄分公司旁边的小餐馆挺符合我口味的…海边休假上周带媳妇娃去她老家海边玩了两天，海边的确很凉快；闺女在游泳池敢于下去玩，海边沙滩不太敢下脚…拿个小水枪在泳池边玩的太开心了；我就比较惨了，在海边玩的没有经验，带了防晒霜根本没有涂，晒黑了许多、背部又痒又痛，现在还感觉有点痒；以后一定记得要防晒；在海边游泳还是很过瘾的、乘着浪晃来晃去的，海水真咸啊！！！]]></content>
      <tags>
        <tag>生活、度假</tag>
        <tag>石家庄</tag>
        <tag>海边游泳</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hyperledger Q&A]]></title>
    <url>%2F2018%2F06%2F08%2Ffabric-1.html</url>
    <content type="text"><![CDATA[hyperledger Q&amp;Ablockchain ledger的数目？每channel 一个？PeerLedger、OrdererLedgerblockchain ledger由world state (KV db) + blockchain 组成world state 由RW set 来执行update，是否要广播同步？不需要，RWSet 是由peer orderer严格验证过的;RWSet 是由peer 根据tx proposal生成的node 的角色clientpeerorderer]]></content>
      <tags>
        <tag>hyperledger 分析</tag>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 详解之一]]></title>
    <url>%2F2018%2F05%2F30%2Fnetty-1.html</url>
    <content type="text"></content>
      <tags>
        <tag>netty 开发实践</tag>
        <tag>netty 架构实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作小结180512]]></title>
    <url>%2F2018%2F05%2F12%2Fweekly-3.html</url>
    <content type="text"><![CDATA[工作小结180512微信小程序微信小程序这一套平台，真是微信的好棋，目前已经是蓬勃发展了啊！我司目前在做一个乘车码的项目，用微信小程序来实现；我认为小程序就是微信平台的H5，给页面文件换个后缀就装奇异果；mpvuempvue 是美团开源的小程序框架，将vue代码翻译为小程序代码；相当于让vue在小程序中运行；666！我大概照着文档改了下我司的小程序项目，的确简化了许多；并且支持ES6，让我这种java程序员感觉宾至如归；node_modules 目录下面的目录密密麻麻的让人头皮发麻…vue &amp; es 6我都是对着文档、示例代码边看边写的，so easy! 具体的等后续再总结]]></content>
      <tags>
        <tag>微信小程序</tag>
        <tag>vue</tag>
        <tag>mpvue</tag>
        <tag>es6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作小结180417]]></title>
    <url>%2F2018%2F04%2F17%2Fweekly-2.html</url>
    <content type="text"><![CDATA[工作小结180417netty websocket返回数据使用 TextWebSocketFrame，刚测试时使用String 返回给client，搞了好久都没有发现；nginx websocketnginx 1.3以后才支持 websocket 转发，我们的运维看错nginx 版本号和对应的测试机器，浪费了一个上午才发现；netty eventloopnetty4.1 的accept 只使用一个线程，即时设置多个也是只用一个线程；（来源于网络文章，未验证）每个IO channel 绑定一个 eventloop，eventloop 对应一个线程；所以就是 IO线程池都是被channel 占用的，如果 业务处理时间较长，则可以将channel 和 线程解绑，deregister方法即可；业务处理完成后，可以重新绑定 eventloop 进行 IO 操作；（上次看的Netty 分析，作个记录）netty 5的文档上说要优化上面这个逻辑的，不过不知道猴年马月；其他将项目的配置文件从属性文件改为 yaml来配置，果然清晰很多；mybatis generator 生成的mapper interface、xml文件不要修改，自己实现的查询、更新等数据库操作都放在另外的mapper代码中；]]></content>
      <tags>
        <tag>netty websocket</tag>
        <tag>nginx websocket</tag>
        <tag>netty channel eventloop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发小结-20180331]]></title>
    <url>%2F2018%2F03%2F31%2Fweekly-1.html</url>
    <content type="text"><![CDATA[开发小结-20180331端口转发命令ssh -CfNg -R 9201:127.0.0.1:8090 root@ip 9201 为服务器端口8090 为本地端口将服务器9201的请求转发到本地8090端口spring boot mvc 设置 httpskeytool -genkey -alias tomcat -dname &quot;CN=Andy,OU=kfit,O=kfit,L=HaiDian,ST=BeiJing,C=CN&quot; -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore keystore.p12 -validity 365 在application.properties中配置HTTPS#https端口号. server.port: 443 #证书的路径. server.ssl.key-store: classpath:keystore.p12 #证书密码，请修改为您自己证书的密码. server.ssl.key-store-password: 123456 #秘钥库类型 server.ssl.keyStoreType: PKCS12 #证书别名 server.ssl.keyAlias: tomcat 微信支付接口验证微信支付接口有两种参数签名方式MD5HmacSHA256有的接口只支持一种，不要搞错；]]></content>
      <tags>
        <tag>spring boot mvc https 配置</tag>
        <tag>微信接口开发</tag>
        <tag>ssh 端口转发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sys-trace-design]]></title>
    <url>%2F2018%2F03%2F11%2Fsys-trace-design.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[区块链学习小结]]></title>
    <url>%2F2018%2F02%2F06%2Fblockchain-1.html</url>
    <content type="text"><![CDATA[区块链学习小结近期看了些比特币、区块链的资料，下载了几分白皮书，看完先总结一些；数据结构Merkle Tree:基于hash值实现树形结构； 参考1Merkle Patricia Tries:以太坊区块中使用的数据结构，MPT实际上是三种数据结构的组合，分别是Trie树， Patricia Trie， 和Merkle树； 参考2P2P：区块链节点间的通信技术，BT下载也是基于这种技术实现；挖矿：计算hash值，这个值在一个范围内；待后续文章详细说一下以太坊的实现；]]></content>
  </entry>
  <entry>
    <title><![CDATA[SRE 实践篇一]]></title>
    <url>%2F2018%2F02%2F06%2Fsre-1.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Hexo 移到 win10]]></title>
    <url>%2F2018%2F02%2F05%2Fhexo-tips.html</url>
    <content type="text"><![CDATA[Hexo 移到 win10之前在Mac本上搭建了hexo环境，配置发布到github,还花了￥150申请了域名；但是一直没写几篇文章，233！（早就猜到是这个结果）这两天打算继续写起来，但是目前主要使用的电脑是win10+ThinkPad t470p(不推荐买这个本，没有为什么)，所以就把hexo安装到win10上，把之前的blog打包过来；这里记录下遇到的几个问题；gifsicle.exe 文件找不到；这个应该是优化生成的blog文章时用到的，我把 _config.yaml 中的 image_minifier enable 改成false; 不使用这个优化，就不会去找那个文件；（解决不了问题，就解决提问题的程序）配置github public key; 一路回车即可（我使用的是git bash）；然后把 ~/.ssh/id_rsa.pub 这个文件写到 github 新建的ssh key 就可以；命令：ssh-keygen -t rsaPaxHeader 乱码文件；我再mac上使用tar打包的，再win10使用7zip解压，结果多了一些 PaxHeader 文件，改成使用zip 压缩就能解决；（用tar 压缩时加上参数也可以解决，搜索时看到的，未测试）MD编辑器使用的是VS code;可以愉快的写blog啦！]]></content>
      <tags>
        <tag>hexo 配置</tag>
        <tag>win10</tag>
        <tag>hexo 部署 github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构实践-集成apollo配置服务]]></title>
    <url>%2F2018%2F01%2F09%2F%E6%9E%B6%E6%9E%84%E5%AE%9E%E8%B7%B5-%E9%9B%86%E6%88%90apollo%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1.html</url>
    <content type="text"><![CDATA[前言近期公司购买了一套XXX系统，准备新业务的拓展；这个新系统中配置文件一堆，还要区分开发、测试、生产等环境；我之前看过Apollo系统的介绍，大概了解一些，这几天认真研究一下，觉得集成到公司业务系统中非常的合适；简介Apollo 是携程研发部门开源的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时的推送到应用端，适用于微服务配置场景。源码地址 github]]></content>
      <tags>
        <tag>系统架构</tag>
        <tag>配置服务Apollo</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC视角下的Spark架构]]></title>
    <url>%2F2017%2F09%2F03%2FRPC%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84Spark%E6%9E%B6%E6%9E%84.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[spark-交易清算]]></title>
    <url>%2F2017%2F07%2F14%2Fspark-%E4%BA%A4%E6%98%93%E6%B8%85%E7%AE%97.html</url>
    <content type="text"><![CDATA[spark 交易清算聚合支付机构的支付后端主要对接的是支付宝、微信支付（京东支付、天翼支付等），清算的数据来源主要是这些机构的对账文件，以及本机构的交易流水；经过我的测试，测试步骤如下：使用parquet保存原始交易数据，使用spark 加载，然后创建temp table对数据表进行查询比对处理在数据量不大的时候（几万条），没有优势；然后我对原始数据保存时又加入了一个分区参数（基于商户号分区），还是没有明显改进；使用MySql 查询时速度很快；本文只是后续记录，测试时具体的时间值我没有保存；因为数据没有索引优化时，spark dataset 的处理不会达到数据库的速度；PS后来看到 Apache Phoenix ，这个应该是可以对数据进行索引的，也能够和spark集成；有空再测试看看；]]></content>
      <tags>
        <tag>spark</tag>
        <tag>聚合支付</tag>
        <tag>交易清算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flink-分布式运行环境]]></title>
    <url>%2F2017%2F07%2F06%2Fflink-%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[DataFlow-编程模型]]></title>
    <url>%2F2017%2F07%2F06%2FDataFlow-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.html</url>
    <content type="text"><![CDATA[Flink的层次模型Flink最底层提供 stateful streaming，是通过Process Function嵌入到DataStream API中实现的；用户能够方便的处理流中的单个或者多个事件，还能够使用一致的容错状态；并且，用户能够注册事件时间和处理时间的回调，允许程序处理复杂的计算；实践中，许多应用不需要使用低层次的接口，而是使用Core APIS如DataStream API（绑定/未绑定的流）和DataSet API(绑定的数据集)。这些流式API提供了数据处理的基本块，如各种用户自定义的转换、连接、聚合、窗口、状态等等函数；这些API中的数据类型在对应的编程语言中都定义为class；集成在DataStream API的底层Process Function，让某些底层操作更加的方便； DataSet API为绑定的数据集提供了更多的操作如loops/iterations;Table API是围绕tables的声明式DSL，可以动态的修改tables;Table API 遵循(扩展的)关系模型；Tables 有一个对应的schema(和关系数据库的表类似)，并且这些API提供了类似的操作如select、project、join、group by、aggregate等等；Table APi程序声明式的定义好应该完成的操作逻辑，而不是明确的对这些操作进行编码；虽然这些Table API被许多自定义的函数扩展（比Core APIs 廉价），但是更加的简洁；更进一步，Table API程序能够在执行前使用优化器进行优化；用户可以在tables 和 DataStream/DataSet 之间无缝的切换，允许程序混合使用这几种APIs;Flink提供的最高层次接口是SQL, 这些和Table API在语义上以及表达上是类似的，只是程序表现为SQL查询表达式；SQL层和Table API密切互动，并且SQL查询能够在Table API对应的表中执行；Programs and DataflowsFlink 程序的基本块是Streams和transformations;(Flink中的DataSet API 也是通过streams实现的)概念上来说，一个流是一系列的数据记录，transformation是接收一个或者多个流作为输入、生成一个或者多个流作为结果；执行时，Flink程序被映射成streaming dataflows, 由streams和transformation operators组成；每个dataflow 从一个或者多个sources开始，结束于一个或者多个sinks;]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>flink</tag>
        <tag>dataflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[预付款系统架构]]></title>
    <url>%2F2017%2F06%2F09%2Fyufuka-sys.html</url>
    <content type="text"></content>
      <tags>
        <tag>预付款系统 架构</tag>
      </tags>
  </entry>
</search>
